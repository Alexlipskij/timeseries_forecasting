{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitfenster mit Generatoren anlernen\n",
    "Beispieldaten: Jena Temperaturen, Kapitel 5.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitung: Daten laden und Datum parsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>...</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:00:00</th>\n",
       "      <td>996.528</td>\n",
       "      <td>-8.304</td>\n",
       "      <td>265.118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1.002</td>\n",
       "      <td>174.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 01:00:00</th>\n",
       "      <td>996.525</td>\n",
       "      <td>-8.065</td>\n",
       "      <td>265.362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.712</td>\n",
       "      <td>172.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 02:00:00</th>\n",
       "      <td>996.745</td>\n",
       "      <td>-8.763</td>\n",
       "      <td>264.645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.607</td>\n",
       "      <td>196.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 03:00:00</th>\n",
       "      <td>996.987</td>\n",
       "      <td>-8.897</td>\n",
       "      <td>264.492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.607</td>\n",
       "      <td>157.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 04:00:00</th>\n",
       "      <td>997.158</td>\n",
       "      <td>-9.348</td>\n",
       "      <td>264.027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.670</td>\n",
       "      <td>150.093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p (mbar)  T (degC)  Tpot (K)  ...  wv (m/s)  \\\n",
       "Date Time                                          ...             \n",
       "2009-01-01 00:00:00   996.528    -8.304   265.118  ...     0.520   \n",
       "2009-01-01 01:00:00   996.525    -8.065   265.362  ...     0.317   \n",
       "2009-01-01 02:00:00   996.745    -8.763   264.645  ...     0.248   \n",
       "2009-01-01 03:00:00   996.987    -8.897   264.492  ...     0.177   \n",
       "2009-01-01 04:00:00   997.158    -9.348   264.027  ...     0.290   \n",
       "\n",
       "                     max. wv (m/s)  wd (deg)  \n",
       "Date Time                                     \n",
       "2009-01-01 00:00:00          1.002   174.460  \n",
       "2009-01-01 01:00:00          0.712   172.417  \n",
       "2009-01-01 02:00:00          0.607   196.817  \n",
       "2009-01-01 03:00:00          0.607   157.083  \n",
       "2009-01-01 04:00:00          0.670   150.093  \n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import ceil\n",
    "\n",
    "pd.set_option('display.max_columns', 6)\n",
    "\n",
    "data_url=r'https://github.com/tplusone/hanser_ml_zeitreihen/blob/master/Daten/jena_climate_complete_hourly.csv?raw=true'\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "### Datum parsen und als Index setzen\n",
    "df['Date Time'] = pd.to_datetime(df['Date Time'])\n",
    "df = df.set_index('Date Time')\n",
    "\n",
    "### Daten zeigen\n",
    "df.head().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) x- und y-Daten extrahieren und in Trainings-/Testpartitionen einteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56104, 14), (14025, 14), (56104, 1), (14025, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.values\n",
    "y = df[['T (degC)']].values\n",
    "X.shape, y.shape\n",
    "\n",
    "## 2. Schritt: Train/Test-Split\n",
    "train_end = ceil(len(X) * 0.8)\n",
    "X_train = X[:train_end]\n",
    "y_train = y[:train_end]\n",
    "\n",
    "X_test = X[train_end:]\n",
    "y_test = y[train_end:]\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Standardisierung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_y.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(X_train)\n",
    "X_train = scaler_x.transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(y_train)\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "joblib.dump(scaler_x, 'scaler_x.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Daten-Generator zur Organisation des Anlernprozesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def data_generator(X, y, window=144, horizon=24, batch_size=1, \n",
    "                   epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        X_temp = []\n",
    "        y_temp = []\n",
    "        batch_counter = 0\n",
    "        last_val = len(X) - (window + horizon)\n",
    "        index_range = list(range(last_val))\n",
    "        random.shuffle(index_range)\n",
    "        for idx in index_range:\n",
    "            X_idx = X[idx:idx+window]\n",
    "            y_idx = y[idx+window+horizon]\n",
    "            X_temp.append(X_idx)\n",
    "            y_temp.append(y_idx)\n",
    "            batch_counter += 1\n",
    "            if (batch_counter == batch_size or \n",
    "                index_range[-1] == idx):\n",
    "                yield np.array(X_temp), np.array(y_temp).reshape(-1)\n",
    "                X_temp = []\n",
    "                y_temp = []\n",
    "                batch_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 144, 14) (1,)\n"
     ]
    }
   ],
   "source": [
    "test_gen = data_generator(X_train, y_train)\n",
    "x_, y_ = next(test_gen)\n",
    "print(x_.shape, y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Aufsetzen und Anlernen des Keras-Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modellarchitektur festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 70, 32)            2720      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70, 32)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                16640     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 19,425\n",
      "Trainable params: 19,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Conv1D, \n",
    "                                    LSTM, Bidirectional)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "reg = l2(0.0001)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=6, strides=2, \n",
    "                input_shape=(144, 14), \n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(units=32, dropout=.3,\n",
    "            kernel_regularizer=reg), input_shape=(144, 14)))            \n",
    "model.add(Dense(units=1, kernel_regularizer=reg))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generatoren und Callbacks definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "window = 144\n",
    "future = 24\n",
    "gen_train = data_generator(X_train, y_train, \n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs)\n",
    "gen_test = data_generator(X_test, y_test, \n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', patience=2)\n",
    "check = ModelCheckpoint(filepath='climate_model.h5', \n",
    "                        monitor='val_loss', save_best_only=True)\n",
    "\n",
    "steps_train = ceil(len(X_train-(window+future))/batch_size)\n",
    "steps_test = ceil(len(X_test-(window+future))/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anlernprozess starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 439 steps, validate for 110 steps\n",
      "Epoch 1/50\n",
      "439/439 [==============================] - 75s 172ms/step - loss: 0.4817 - mae: 0.5100 - val_loss: 0.4053 - val_mae: 0.4732\n",
      "Epoch 2/50\n",
      "439/439 [==============================] - 67s 152ms/step - loss: 0.3963 - mae: 0.4622 - val_loss: 0.3964 - val_mae: 0.4736\n",
      "Epoch 3/50\n",
      "439/439 [==============================] - 66s 150ms/step - loss: 0.3496 - mae: 0.4343 - val_loss: 0.4307 - val_mae: 0.5082\n",
      "Epoch 4/50\n",
      "439/439 [==============================] - 65s 149ms/step - loss: 0.3216 - mae: 0.4158 - val_loss: 0.4240 - val_mae: 0.5022\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(gen_train, epochs=epochs, \n",
    "             steps_per_epoch=steps_train, \n",
    "             validation_data=(gen_test), \n",
    "             validation_steps=steps_test,\n",
    "             callbacks=[early, check])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_vs_true(X_pred, y_true, model, scaler,\n",
    "                        window=144, horizon=24):\n",
    "    X_temp = []\n",
    "    y_temp = []\n",
    "    y_temp_simple = []\n",
    "    num_pred = len(X_pred)-(window+horizon)\n",
    "    for idx in range(num_pred):\n",
    "        X_idx = X_pred[idx:idx+window]\n",
    "        y_idx = y_true[idx+window+horizon]\n",
    "        X_temp.append(X_idx)\n",
    "        y_temp.append(y_idx)\n",
    "        y_temp_simple.append(y_true[idx+window])\n",
    "    X_temp = np.array(X_temp)\n",
    "    y_pred = model.predict(X_temp)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_temp = scaler.inverse_transform(y_temp)\n",
    "    y_temp_simple = scaler.inverse_transform(y_temp_simple)\n",
    "    return y_temp, y_pred, y_temp_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae, predictions 4.0222062736252475\n",
      "mae, simple pred 4.209516369584565\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "model = load_model('climate_model.h5')\n",
    "y_true, y_pred, y_temp_simple = predictions_vs_true(X_test, \n",
    "                                    y_test, \n",
    "                                    model=model, \n",
    "                                    scaler=scaler_y)\n",
    "                                     \n",
    "print('mae, predictions', mean_absolute_error(y_true, y_pred))\n",
    "print('mae, simple pred', mean_absolute_error(y_true, y_temp_simple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
